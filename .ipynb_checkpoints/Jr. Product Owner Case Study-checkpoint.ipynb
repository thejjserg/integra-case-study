{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6c508d2",
   "metadata": {},
   "source": [
    "This document will highlight the **Jr. Product Owner: Case Study** for **Integra Partners**.\n",
    "\n",
    "We will first review the scenarios and related tasks, then present a mock example using randomly generated data.\n",
    "\n",
    "# Scenario\n",
    "You are the Junior Product Owner responsible for managing a Tier 1 Support Team that handles day-to-day user requests for a cloud-based application. Over the past month, your team has received an increasing number of support tickets related to intermittent login failures. While these issues are being resolved individually, the volume of tickets is growing, and some users are becoming frustrated with the frequency of this problem.\n",
    "\n",
    "Your role is to determine how best to address this situation and ensure it doesn’t become a recurring issue."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe81e434",
   "metadata": {},
   "source": [
    "## Task 1: Data Analysis and Trend Identification\n",
    "Analyze the data from the past month’s support tickets. You notice that many login failure issues come from specific user groups, particularly those accessing the system during peak hours. There are similarities in the error messages these users report, suggesting a potential pattern or underlying issue.\n",
    "\n",
    "1. What specific data would you prioritize further to investigate the root cause of these login failures?\n",
    "2. Based on the data, what trends can you identify, and\n",
    "3. How would you use this information to escalate the issue to the Tier 3 Support Team for futher investigation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5c759",
   "metadata": {},
   "source": [
    "First, we believe that **Timestamps of Failures**, **Error Types**, and **User Environment** are the top 3 areas we can prioritize first. \n",
    "\n",
    "- **Timestamps of Failures** can help with visualizing spikes in errors and help determine if there are server capacity limits in our systems. Timestamps can help us pinpoint which specific timeframe we are seeing issues. Perhaps there is heavy traffic at specific timeframes and the system is overloaded and is not scaling well. This could be a sign that additional server resources are required and the infrastructure team will need to be engaged.\n",
    "\n",
    "- **Error Types** can show the nature of issues and types of errors we are receiving. These can be **Timeouts**, **Service Unavailable**, **Authentication Failed**, or any other types of errors. The Error Types can suggest backend issues, like an authentication service failure or delayed response from the server. Tabulating the number of specific requests can help point the Tier 3 system in the right direction in resolving the issues.\n",
    "\n",
    "- **User Environment** is important because it can show various configuration issues. For example, perhaps, there is a difference in issues reported for Windows vs Mac or different browser options. If specific user groups are experiencing more failures, then there may be a network-related issue (slow VPN connections, regional server problems, or something else) or inconsistent system configuration for our users.\n",
    "\n",
    "When escalating to a Tier 3 Support Team, we would provide the **overall problem** and highlight the **business value**. We would visualize the number of errors and error types, highlight the spikes of errors between 8am - 6pm, and make note of the errors based on environment. We would also quantify the monetary business value and business impact of time loss and overall morale of wasted time for the affected users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7545af",
   "metadata": {},
   "source": [
    "As we are not provided specific data on the problems **Integra Partners** are facing, we will create randomly generated test data for our report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6865aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[1;32m      6\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;66;03m# Set the seed for generating the same random data.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import csv # Python library used for reading and writing tabular data in CSV format.\n",
    "import pandas as pd # Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data. \n",
    "import json # Python library for encoding and decoding custom objects by using JSON encoder and decoder classes.\n",
    "import numpy as np # Python library for adding support to large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "import seaborn as sns #Python library for statistical visualizations\n",
    "import statistics as stat #Python library for statistical operations\n",
    "import matplotlib.pyplot as plt # Python library for creating graphs\n",
    "import random # Python library for generating random data\n",
    "\n",
    "from scipy import stats # Python library for linear regression\n",
    "from datetime import datetime, timedelta # Python library used for dates and time\n",
    "\n",
    "random.seed(4) # Set the seed for generating the same random data.\n",
    "np.random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb826ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for random generation\n",
    "user_groups = ['Finance', 'Sales', 'HR', 'IT', 'Marketing', 'Operations']\n",
    "error_messages = ['Invalid credentials', '503 Service Unavailable', 'Session timeout', 'User not found', 'Network error', 'CAPTCHA failed']\n",
    "locations = ['Office', 'Remote']\n",
    "devices = ['Desktop', 'Mobile', 'Tablet']\n",
    "browsers = ['Chrome 87', 'Firefox 95', 'Edge 92', 'Safari 14', 'Opera 75']\n",
    "root_causes = ['User error', 'Network issue', 'System downtime', 'Server overload', 'Firewall block']\n",
    "resolution_steps = ['Password reset', 'Clear cache', 'Network reset', 'Escalated to Tier 3', 'Restart system']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "data = []\n",
    "start_date = datetime.now() - timedelta(days=30)\n",
    "\n",
    "for i in range(50):\n",
    "    ticket_id = f\"TID{i+1:03d}\"\n",
    "    user_group = random.choice(user_groups)\n",
    "    user_id = f\"U{random.randint(1000, 9999)}\"\n",
    "    error_message = random.choice(error_messages)\n",
    "    date_time_of_issue = start_date + timedelta(days=random.randint(0, 29), hours=random.randint(0, 23), minutes=random.randint(0, 59))\n",
    "    login_attempt_time = date_time_of_issue + timedelta(minutes=random.randint(-10, 10))\n",
    "    location = random.choice(locations)\n",
    "    device_type = random.choice(devices)\n",
    "    browser_version = random.choice(browsers)\n",
    "    resolution_time = date_time_of_issue + timedelta(minutes=random.randint(30, 120))\n",
    "    escalation_status = 'Yes' if random.random() < 0.3 else 'No'\n",
    "    root_cause = random.choice(root_causes)\n",
    "    resolution_steps_taken = random.choice(resolution_steps)\n",
    "    sla_compliance = 'Yes' if resolution_time - date_time_of_issue <= timedelta(hours=1) else 'No'\n",
    "    additional_notes = \"Issue resolved\" if escalation_status == 'No' else \"Escalated to Tier 3\"\n",
    "\n",
    "    data.append([ticket_id, user_group, user_id, error_message, date_time_of_issue, login_attempt_time, location, device_type, browser_version, \n",
    "                 resolution_time, escalation_status, root_cause, resolution_steps_taken, sla_compliance, additional_notes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "columns = ['Ticket ID', 'User Group', 'User ID', 'Error Message', 'Date and Time of Issue', 'Login Attempt Time', \n",
    "           'Location', 'Device Type', 'Browser/OS Version', 'Resolution Time', 'Escalation Status', \n",
    "           'Root Cause', 'Resolution Steps Taken', 'SLA Compliance', 'Additional Notes']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
